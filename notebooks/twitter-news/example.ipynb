{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ardit\\miniconda3\\envs\\env1\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# move directory to the root of this repo\n",
    "os.chdir('\\\\'.join(os.getcwd().split('\\\\')[:-2]))\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from simtag.filter import simtag_filter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# list of tweets, already formatted in parquet format for easy loading\n",
    "df = pd.read_csv('notebooks/twitter-news/news_tweets.csv', lineterminator='\\n')\n",
    "df = df.dropna(subset='hashtags')\n",
    "df = df.reset_index()\n",
    "df['hashtags'] = df['hashtags'].apply(lambda x : ast.literal_eval(x))\n",
    "sample_list = df['hashtags'].tolist()\n",
    "\n",
    "# extract hashtags\n",
    "hashtags_list = [x for x in df['hashtags'].dropna()]\n",
    "hashtags = list()\n",
    "[[hashtags.append(k) for k in x] for x in hashtags_list]\n",
    "hashtags = list(set(hashtags))\n",
    "hashtags = sorted(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate recommender\n",
    "engine = simtag_filter(\n",
    "    sample_list=sample_list,\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    quantization='int8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M, valid_tags, pointers = engine.compute_optimal_M(verbose=True, percentile_threshold=95, n_clusters=1000, quantize_M=True)\n",
    "\n",
    "# store pre-computed files\n",
    "# engine.npy_save(M, 'notebooks/twitter-news/M_quantized')\n",
    "# engine.json_save(pointers, 'notebooks/twitter-news/pointers')\n",
    "\n",
    "# load pre-computed files\n",
    "M = engine.npy_load('notebooks/twitter-news/M_quantized')\n",
    "pointers = engine.json_load('notebooks/twitter-news/pointers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.load_M(M, pointers, covariate_transformation='dot_product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing samples: 100%|██████████| 73137/73137 [01:17<00:00, 946.67it/s] \n"
     ]
    }
   ],
   "source": [
    "# prepare search\n",
    "sample_vectors = engine.encode_samples(sample_list)\n",
    "index_covariate = engine.compute_search_indexes(sample_vectors, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nft', 'crypto']\n",
      "['cryptogaming', 'cryptosport', 'cryptosportgaming', 'NftAnalysis']\n",
      "['cryptogaming', 'cryptosport', 'cryptosportgaming', 'NftReview']\n",
      "['cryptogaming', 'cryptosport', 'cryptosportgaming', 'BestNft']\n",
      "['nft', 'crypto']\n",
      "['nft', 'crypto']\n",
      "['NFT', 'crypto']\n",
      "['NFT', 'Crypto']\n",
      "['CryptoNews', 'NFTs']\n",
      "['Crypto', 'CryptoLegions', 'cryptocurrency', 'ETH', 'NFTProject', 'NFTCommumity']\n"
     ]
    }
   ],
   "source": [
    "query_tag_list = ['crypto', 'nft']\n",
    "indices, search_results = engine.covariate_search(index_covariate, sample_list, query_tag_list=query_tag_list, allow_new_tags=True, print_new_tags=True, k=10)\n",
    "for k in search_results[0:10]:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cryptogaming', 'cryptosport', 'cryptosportgaming', 'BestNft']\n",
      "['nft', 'crypto']\n",
      "['nft', 'crypto']\n",
      "['cryptogaming', 'cryptosport', 'cryptosportgaming', 'NftReview']\n",
      "['NFT', 'Crypto']\n",
      "['NFT', 'crypto']\n",
      "['cryptogaming', 'cryptosport', 'cryptosportgaming', 'NftAnalysis']\n",
      "['nft', 'crypto']\n",
      "['NFT', 'OpenSea', 'Cryptocurrency']\n",
      "['Ethereum', 'Ethereum', 'Cryptocurency', 'NFTs', 'trading']\n"
     ]
    }
   ],
   "source": [
    "# M_256 does not perform well on semantic-covariate encoding\n",
    "indices, search_results = engine.semantic_covariate_search(index_covariate, sample_list, query=\"I want to buy crypto and nft\", k=10)\n",
    "for k in search_results[0:10]:\n",
    "    print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
