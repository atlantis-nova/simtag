{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ardit\\miniconda3\\envs\\env1\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# move directory to the root of this repo\n",
    "os.chdir('\\\\'.join(os.getcwd().split('\\\\')[:-2]))\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from simtag.filter import simtag_filter\n",
    "import pandas as pd\n",
    "\n",
    "def import_batch_parquet(batch_prefix):\n",
    "\tdfs = [pd.read_parquet(f'{batch_prefix}{i}.parquet') for i in range(5)]\n",
    "\tdf = pd.concat(dfs, ignore_index=True)\n",
    "\treturn df\n",
    "\n",
    "def store_batch_parquet(df, batch_prefix):\n",
    "\tchunk_size = len(df) // 5\n",
    "\tfor i in range(5):\n",
    "\t\tstart = i * chunk_size\n",
    "\t\tend = (i + 1) * chunk_size if i < 4 else len(df)\n",
    "\t\tdf.iloc[start:end].to_parquet(f\"{batch_prefix}{i}.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# list of tweets, already formatted in parquet format for easy loading\n",
    "df = pd.read_csv('notebooks/twitter-news/news_tweets.csv', lineterminator='\\n')\n",
    "df = df.dropna(subset='hashtags')\n",
    "df = df.reset_index()\n",
    "df['hashtags'] = df['hashtags'].apply(lambda x : ast.literal_eval(x))\n",
    "sample_list = df['hashtags'].tolist()\n",
    "\n",
    "# extract hashtags\n",
    "hashtags_list = [x for x in df['hashtags'].dropna()]\n",
    "hashtags = list()\n",
    "[[hashtags.append(k) for k in x] for x in hashtags_list]\n",
    "hashtags = list(set(hashtags))\n",
    "hashtags = sorted(hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate recommender\n",
    "engine = simtag_filter(\n",
    "    sample_list=sample_list,\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    quantization='int8'\n",
    ")\n",
    "tag2index, indexed_sample_list = engine.index_samples(sample_list) # used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not existing, compute and save M\n",
    "# M, df_M = engine.compute_M(method='encoding')\n",
    "# store as batches, you can store as a unique file if you wish\n",
    "# store_batch_parquet(df_M, 'notebooks/twitter-news/M_')\n",
    "\n",
    "# if existing, load M\n",
    "df_M = import_batch_parquet(batch_prefix='notebooks/twitter-news/M_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.load_M(df_M, covariate_transformation='dot_product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not existing, compute and save samples_encoded.parquet\n",
    "# sample_vectors = engine.encode_samples(sample_list)\n",
    "# samples_encoded = pd.DataFrame([sample_vectors], index=['vector']).T\n",
    "# store_batch_parquet(samples_encoded, 'notebooks/twitter-news/quantized_samples_encoded_')\n",
    "\n",
    "# if already existing, load samples_encoded.parquet\n",
    "samples_encoded = import_batch_parquet(batch_prefix='notebooks/twitter-news/samples_encoded_')\n",
    "sample_vectors = samples_encoded.vector.tolist()\n",
    "nbrs_covariate = engine.compute_nbrs(sample_vectors, k=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def compute_html(query_tag_list, sample_list, search_indices, covariate_indices, k, t, display_code=True, return_code=False):\n",
    "\t'''\n",
    "\tt : the number of samples in tag_search_results from where we pick the dark red words\n",
    "\t'''\n",
    "\n",
    "\thtml_list = list()\n",
    "\t# complete_html = ''\n",
    "\tfor search_index in range(k):\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tsample_index = search_indices[search_index]\n",
    "\t\t\ttag_search_results = [sample_list[x] for x in covariate_indices[0:t]]\n",
    "\t\t\tdata = sample_list[sample_index]\n",
    "\t\t\ttop_tag_list = set([item for items in tag_search_results[0:t] for item in items])\n",
    "\n",
    "\t\t\tscore = 0\n",
    "\t\t\thtml_code = ''\n",
    "\n",
    "\t\t\tfor word in data:\n",
    "\t\t\t\t\n",
    "\t\t\t\tif word in query_tag_list:\n",
    "\t\t\t\t\tscaled_intensity = 1\n",
    "\t\t\t\t\tscore += 1\n",
    "\t\t\t\telif word in top_tag_list:\n",
    "\t\t\t\t\tscaled_intensity = 0.6\n",
    "\t\t\t\t\tscore += 0.5\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tscaled_intensity = 0\n",
    "\t\t\t\t\tscore -= 0.3\n",
    "\t\t\t\tg = int(20 * (1 - scaled_intensity))\n",
    "\t\t\t\tr = int(255 * scaled_intensity * 0.7)  # adjust the green component\n",
    "\t\t\t\tcolor = f\"rgb({r},{g},0)\"\n",
    "\t\t\t\thtml_code += f\"<span style='background-color:{color}; color:white'><b>{word}<b></span> \"\n",
    "\t\t\t\t# html_code += f\"<span style='color:{color}'>{word}</span> \"\n",
    "\n",
    "\t\t\tscore = float(round(score, 4))\n",
    "\t\t\thtml_full = '<b>'+str(score)+' - '+html_code+'<br>'\n",
    "\t\t\t\n",
    "\t\texcept Exception as e:\n",
    "\t\t\t# print('ERR', e)\n",
    "\t\t\thtml_full = ''\n",
    "\t\t\t# complete_html += ''\n",
    "\n",
    "\t\thtml_list.append([score, html_full])\n",
    "\t\t\n",
    "\thtml_list = sorted(html_list)[::-1]\n",
    "\thtml_list = [x[1] for x in html_list]\n",
    "\n",
    "\tif display_code : [display(HTML(x)) for x in html_list]\n",
    "\n",
    "\tif return_code : return html_list\n",
    "\n",
    "def compute_indices(query_tag_list, tag2index, indexed_sample_list, nbrs_semantic=None, nbrs_covariate=None, search_types=['hard', 'jaccard', 'covariate', 'semantic', 'covariate_semantic']):\n",
    "\t# hard search\n",
    "\tindices_hard = engine.hard_tag_filtering(tag2index, indexed_sample_list, query_tag_list, search_type='AND')\n",
    "\n",
    "\t# jaccard search\n",
    "\tindices_jaccard = engine.hard_tag_filtering(tag2index, indexed_sample_list, query_tag_list, search_type='OR')\n",
    "\n",
    "\t# covariate search\n",
    "\tquery_vector = engine.encode_query(list_tags=query_tag_list, allow_new_tags=True, print_new_tags=True)\n",
    "\tindices_covariate, tag_search_results = engine.soft_tag_filtering(nbrs_covariate, sample_list, query_vector)\n",
    "\n",
    "\t# semantic search\n",
    "\tif nbrs_semantic is not None:\n",
    "\t\tquery_vector = engine.model.encode(str(query_tag_list))\n",
    "\t\tindices_semantic, search_results = engine.soft_tag_filtering(nbrs_semantic, sample_list, query_vector)\n",
    "\telse:\n",
    "\t\tindices_semantic = np.array([])\n",
    "\n",
    "\t# covariate semantic search\n",
    "\ttry:\n",
    "\t\tquery_vector = engine.model.encode(str(query_tag_list))\n",
    "\t\tindices_covariate_semantic, search_results = engine.soft_tag_filtering(nbrs_covariate, sample_list, query_vector)\n",
    "\texcept:\n",
    "\t\tindices_covariate_semantic = np.array([])\n",
    "\n",
    "\tindices = dict()\n",
    "\tif 'hard' in search_types:\n",
    "\t\tindices['hard'] = indices_hard\n",
    "\tif 'jaccard' in search_types:\n",
    "\t\tindices['jaccard'] = indices_jaccard\n",
    "\tif 'covariate' in search_types:\n",
    "\t\tindices['covariate'] = indices_covariate\n",
    "\tif 'semantic' in search_types:\n",
    "\t\tindices['semantic'] = indices_semantic\n",
    "\tif 'covariate_semantic' in search_types:\n",
    "\t\tindices['covariate_semantic'] = indices_covariate_semantic\n",
    "\treturn indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2247], dtype=int64)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tag_list=['democrats']\n",
    "indices = compute_indices(query_tag_list=['democracy', 'Republicans'], indexed_sample_list=indexed_sample_list, tag2index=tag2index, nbrs_covariate=nbrs_covariate, search_types=['hard', 'jaccard', 'covariate'])\n",
    "indices['hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>4.5 - <span style='background-color:rgb(107,8,0); color:white'><b>democracy<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>news<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>America<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>propaganda<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>uniparty<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>fakenews<b></span> <span style='background-color:rgb(178,0,0); color:white'><b>democrats<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_html(query_tag_list, sample_list, indices['hard'], indices['covariate'], k=7, t=7, display_code=True, return_code=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>4.5 - <span style='background-color:rgb(107,8,0); color:white'><b>democracy<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>news<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>America<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>propaganda<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>uniparty<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>fakenews<b></span> <span style='background-color:rgb(178,0,0); color:white'><b>democrats<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>1.0 - <span style='background-color:rgb(107,8,0); color:white'><b>FBI<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>0.4 - <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>Trump<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>BREAKING<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>news<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>0.2 - <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>MAGAMORONS<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>0.2 - <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>IRS<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>-0.4 - <span style='background-color:rgb(0,20,0); color:white'><b>trump<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>truth<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>RuleOfLaw<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>democracy<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>-0.7 - <span style='background-color:rgb(0,20,0); color:white'><b>American<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>media<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>journalists<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Democrat<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>Obama<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>BLM<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>democracy<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>Kentucky<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>FreePress<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>news<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>MSNBCprime<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>cnnprime<b></span> <span style='background-color:rgb(0,20,0); color:white'><b>CBSENews<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_html(query_tag_list, sample_list, indices['jaccard'], indices['covariate'], k=7, t=7, display_code=True, return_code=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>4.5 - <span style='background-color:rgb(107,8,0); color:white'><b>democracy<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>news<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>America<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>propaganda<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>uniparty<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>fakenews<b></span> <span style='background-color:rgb(178,0,0); color:white'><b>democrats<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3.0 - <span style='background-color:rgb(107,8,0); color:white'><b>politics<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>MIDTERMS<b></span> <span style='background-color:rgb(178,0,0); color:white'><b>democrats<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>democracy<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>BLM<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3.0 - <span style='background-color:rgb(107,8,0); color:white'><b>Blacks<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Democrats<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Independents<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>politics<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>news<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2.0 - <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>GOP<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>FBI<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Democratic<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>1.0 - <span style='background-color:rgb(107,8,0); color:white'><b>Republicans<b></span> <span style='background-color:rgb(107,8,0); color:white'><b>Democrat<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>0.5 - <span style='background-color:rgb(107,8,0); color:white'><b>Democratic<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>0.5 - <span style='background-color:rgb(107,8,0); color:white'><b>Democracy<b></span> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_html(query_tag_list, sample_list, indices['covariate'], indices['covariate'], k=7, t=7, display_code=True, return_code=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ignored search data\n",
    "\n",
    "We compute the amount of data that gets ignored when performing a classic search compared with a covariate search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def count_frequency(search_results):\n",
    "\tflat_list = list(itertools.chain.from_iterable(search_results))\n",
    "\tfreq_count = Counter(flat_list)\n",
    "\tsorted_freq_count = sorted(freq_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\treturn sorted_freq_count\n",
    "\n",
    "count_frequency(sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "query_tag_list = ['trump', 'Putin', 'Russia', 'Politics', 'China', 'FBI']\t\t\t\t# .35 data is never considered\n",
    "# query_tag_list = ['BTC', 'bitcoin', 'crypto', 'investment']\t\t\t\t\t\t\t# .16 data is never considered\n",
    "# query_tag_list = ['100DaysOfCode', 'coding', 'Robotics', 'dailybites', 'Learnings']\t# .57 data is never considered\n",
    "\n",
    "# perform search\n",
    "query_vector = engine.encode_query(list_tags=query_tag_list, allow_new_tags=True, print_new_tags=True, ignore_weights=True)\n",
    "indices, search_results = engine.soft_tag_filtering(nbrs_covariate, sample_list, query_vector)\n",
    "len(search_results)\n",
    "# count_frequency(search_results[0:1000])[0:10]\n",
    "\n",
    "# traditional search\n",
    "hard_indices, hard_filter_results = engine.jaccard_tag_filtering(sample_list, query_tag_list)\n",
    "\n",
    "### SAMPLES THAT CAN ONLY BE FOUND WITH SIMTAG\n",
    "missing = list()\n",
    "for index in indices:\n",
    "\tif index not in hard_indices:\n",
    "\t   \tmissing.append(sample_list[index])\n",
    "\n",
    "def compute_sim_score(query_tag_list, to_compute, benchmark=0, benchmarks_limit=None):\n",
    "\n",
    "\tlimit_counter = 0\n",
    "\ttemp_benchmark = benchmark\n",
    "\n",
    "\tsample_scores = list()\n",
    "\tfor sample_missing in tqdm(to_compute):\n",
    "\t\tlist1 = list()\n",
    "\t\tfor q in query_tag_list:\n",
    "\t\t\tq_list = list()\n",
    "\t\t\tfor m in sample_missing:\n",
    "\t\t\t\t# print(q, m)\n",
    "\t\t\t\tq_list.append(cos_sim(get_vector(q), get_vector(m)).tolist()[0][0])\n",
    "\t\t\tlist1.append(q_list)\n",
    "\t\tavg_score = statistics.mean([max(x) for x in list1])\n",
    "\n",
    "\t\tif avg_score < benchmark:\n",
    "\t\t\tlimit_counter +=1\n",
    "\t\t\t# we set the new benchmark\n",
    "\t\t\tif avg_score < temp_benchmark:\n",
    "\t\t\t\ttemp_benchmark = avg_score\n",
    "\t\t\t\t# we reset the counter, because we found a new low\n",
    "\t\t\t\tlimit_counter = 0\n",
    "\n",
    "\t\tsample_scores.append(avg_score)\n",
    "\n",
    "\t\tif benchmarks_limit is not None:\n",
    "\t\t\tif limit_counter >= benchmarks_limit:\n",
    "\t\t\t\t# break the cycle\n",
    "\t\t\t\treturn sample_scores\n",
    "\t\t\n",
    "\treturn sample_scores\n",
    "\n",
    "def get_vector(tag):\n",
    "\treturn engine.df_M[engine.df_M['tags']==tag]['vector_tags'].values[0]\n",
    "\n",
    "# compute benchmark\n",
    "# tag_vector = engine.encode_query(list_tags=query_tag_list, allow_new_tags=False)\n",
    "# sample_vector = engine.encode_query(list_tags=hard_filter_results[-1], allow_new_tags=False)\n",
    "# benchmark = cos_sim(tag_vector, sample_vector).tolist()[0][0]\n",
    "\n",
    "benchmark_scores = compute_sim_score(query_tag_list, hard_filter_results[-50:])\n",
    "benchmark = min(benchmark_scores)\n",
    "\n",
    "to_compute = missing[0:4000]\n",
    "sample_scores = compute_sim_score(query_tag_list, to_compute, benchmark, benchmarks_limit=350)\n",
    "df_missing = pd.DataFrame([to_compute, sample_scores]).T.sort_values(1, ascending=False)\n",
    "\n",
    "df_missing_filtered = df_missing[df_missing[1]>benchmark]\n",
    "len_missing = len(df_missing_filtered)\n",
    "len_hard = len(hard_filter_results)\n",
    "\n",
    "# percentage of valid sample missed\n",
    "print('samples found:\\t\\t', len_hard)\n",
    "print('sample missing:\\t\\t',len_missing)\n",
    "print('% of data ignored:\\t',round(len_missing/(len_missing+len_hard), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# create a histogram with 5 bins\n",
    "fig = px.histogram(x=df_missing[1], nbins=100)\n",
    "fig.update_xaxes(autorange=\"reversed\")\n",
    "\n",
    "# show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all search results that cannot be found using traditional search algos\n",
    "# ex. ['trump', 'Putin', 'Russia', 'Politics', 'China', 'FBI']\n",
    "df_missing_filtered[0].values.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
